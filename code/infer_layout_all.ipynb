{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install yacs\n",
    "!pip install gdown\n",
    "!pip install opencv-python\n",
    "!pip install torchvision\n",
    "!pip install open3d\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import importlib\n",
    "import imageio.v3 as iio\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import correlate2d\n",
    "from scipy.ndimage import shift\n",
    "from skimage.transform import resize\n",
    "\n",
    "from lib.config import config\n",
    "from eval_layout import layout_2_depth\n",
    "from lib.misc.post_proc import np_coor2xy, np_coorx2u, np_coory2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download pretrained\n",
    "- We use HoHoNet w/ hardnet encoder in this demo\n",
    "- Download other version [here](https://drive.google.com/drive/folders/1raT3vRXnQXRAQuYq36dE-93xFc_hgkTQ?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PRETRAINED_PTH = './HoHoNet/ckpt/mp3d_layout_HOHO_layout_aug_efficienthc_Transen1_resnet34/ep300.pth'\n",
    "\n",
    "if not os.path.exists(PRETRAINED_PTH):\n",
    "    os.makedirs(os.path.split(PRETRAINED_PTH)[0], exist_ok=True)\n",
    "    !gdown 'https://drive.google.com/uc?id=1OU9uyuNiswkPovJuvG3sevm3LqHJgazJ' -O $PRETRAINED_PTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download image\n",
    "- We use a out-of-distribution image from PanoContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists('./HoHoNet/assets/pano_asmasuxybohhcj.png'):\n",
    "    !gdown 'https://drive.google.com/uc?id=1CXl6RPK6yPRFXxsa5OisHV9KwyRcejHu' -O './HoHoNet/panocontext/pano_asmasuxybohhcj.png'\n",
    "\n",
    "# Create dataset\n",
    "path_dir = './HoHoNet/assets/Pano/'\n",
    "dataset = sorted(glob.glob(os.path.join(path_dir, '*jpg')))\n",
    "\n",
    "# Visualize an example\n",
    "bgr = cv2.imread(os.path.join('./HoHoNet/panocontext/pano_asmasuxybohhcj.png'))\n",
    "rgb = bgr[:,:,::-1]\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load model config\n",
    "- We use HoHoNet w/ hardnet encoder in this demo\n",
    "- Find out other version in `mp3d_depth/` and `s2d3d_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load model config\n",
    "config.defrost()\n",
    "config.merge_from_file('./HoHoNet/config/mp3d_layout/HOHO_layout_aug_efficienthc_Transen1_resnet34.yaml')\n",
    "config.freeze()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device:', device)\n",
    "\n",
    "# Load model\n",
    "model_file = importlib.import_module(config.model.file)\n",
    "model_class = getattr(model_file, config.model.modelclass)\n",
    "net = model_class(**config.model.kwargs)\n",
    "net.load_state_dict(torch.load(PRETRAINED_PTH, map_location=device))\n",
    "net = net.eval().to(device)\n",
    "\n",
    "# 3D\n",
    "H, W = 256, 512\n",
    "ignore_floor = False\n",
    "ignore_ceiling = True\n",
    "ignore_wall = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize result in 2d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize result in 2d\n",
    "for i in dataset:\n",
    "\n",
    "    # Extract name\n",
    "    name0 = i.replace('.jpg', '').replace('./HoHoNet/assets/Pano', '')\n",
    "    name1 = name0.replace('\\\\', '')\n",
    "    name2 = name1.replace(' ', '_')\n",
    "    print('name1: ', name1)\n",
    "\n",
    "    # Resize panoramic\n",
    "    bgr = cv2.imread(os.path.join(i))\n",
    "    rgb = bgr[:,:,::-1]\n",
    "    rgb_resize = cv2.resize(rgb, (1024, 512), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Move image into tensor, normalize to [0, 255], resize to 512x1024\n",
    "    x = torch.from_numpy(rgb_resize).permute(2,0,1)[None].float() / 255.\n",
    "    if x.shape[2:] != config.dataset.common_kwargs.hw:\n",
    "        x = torch.nn.functional.interpolate(x, config.dataset.common_kwargs.hw, mode='area')\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Model feedforward\n",
    "    with torch.no_grad():\n",
    "        ts = time.time()\n",
    "        layout = net.infer(x)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        print(f'Eps time: {time.time() - ts:.2f} sec.')\n",
    "\n",
    "    cor_id = layout['cor_id']\n",
    "    y_bon_ = layout['y_bon_']\n",
    "    y_cor_ = layout['y_cor_']\n",
    "\n",
    "    # Visualize result in 2d\n",
    "    image1 = np.concatenate([\n",
    "        (y_cor_ * 255).reshape(1,-1,1).repeat(0, 0).repeat(3, 2).astype(np.uint8),\n",
    "        rgb_resize[:]\n",
    "    ], 0)\n",
    "    image2 = layout_2_depth(cor_id, *rgb_resize.shape[:2])\n",
    "\n",
    "    plt.figure(figsize=(15,6))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image1)\n",
    "    plt.plot(np.arange(y_bon_.shape[1]), y_bon_[0], 'r-')\n",
    "    plt.plot(np.arange(y_bon_.shape[1]), y_bon_[1], 'r-')\n",
    "    plt.scatter(cor_id[:, 0], cor_id[:, 1], marker='x', c='b')\n",
    "    plt.axis('off')\n",
    "    plt.title('y_bon_ (red) / y_cor_ (up-most bar) / cor_id (blue x)')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image2, cmap='inferno_r')\n",
    "    plt.axis('off')\n",
    "    plt.title('rendered depth from the estimated layout (cor_id)')\n",
    "\n",
    "\n",
    "    # Save layout prediction\n",
    "    plt.imsave(f'./HoHoNet/assets/output/layout/{name2}_layout.png', image2, format='png', cmap='inferno_r')\n",
    "\n",
    "    # Save figure\n",
    "    plt.draw()\n",
    "    plt.savefig(f'./HoHoNet/assets/output/result/layout/{name2}_result_layout.png', format='png', cmap='inferno_r')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Convert corners to layout\n",
    "    depth, floor_mask, ceil_mask, wall_mask = [\n",
    "        resize(v, [H, W], order=0, preserve_range=True).astype(v.dtype)\n",
    "        for v in layout_2_depth(cor_id, *rgb_resize.shape[:2], return_mask=True)]\n",
    "    coorx, coory = np.meshgrid(np.arange(W), np.arange(H))\n",
    "    us = np_coorx2u(coorx, W)\n",
    "    vs = np_coory2v(coory, H)\n",
    "    zs = depth * np.sin(vs)\n",
    "    cs = depth * np.cos(vs)\n",
    "    xs = cs * np.sin(us)\n",
    "    ys = -cs * np.cos(us)\n",
    "\n",
    "    # Aggregate mask\n",
    "    mask = np.ones_like(floor_mask)\n",
    "    if ignore_floor:\n",
    "        mask &= ~floor_mask\n",
    "    if ignore_ceiling:\n",
    "        mask &= ~ceil_mask\n",
    "    if ignore_wall:\n",
    "        mask &= ~wall_mask\n",
    "\n",
    "    # Prepare ply's points and faces\n",
    "    xyzrgb = np.concatenate([\n",
    "        xs[...,None], ys[...,None], zs[...,None],\n",
    "        resize(rgb_resize, [H, W])], -1)\n",
    "    xyzrgb = np.concatenate([xyzrgb, xyzrgb[:,[0]]], 1)\n",
    "    mask = np.concatenate([mask, mask[:,[0]]], 1)\n",
    "    lo_tri_template = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 1]])\n",
    "    up_tri_template = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]])\n",
    "    ma_tri_template = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 1, 0]])\n",
    "    lo_mask = (correlate2d(mask, lo_tri_template, mode='same') == 3)\n",
    "    up_mask = (correlate2d(mask, up_tri_template, mode='same') == 3)\n",
    "    ma_mask = (correlate2d(mask, ma_tri_template, mode='same') == 3) & (~lo_mask) & (~up_mask)\n",
    "    ref_mask = (\n",
    "        lo_mask | (correlate2d(lo_mask, np.flip(lo_tri_template, (0,1)), mode='same') > 0) |\\\n",
    "        up_mask | (correlate2d(up_mask, np.flip(up_tri_template, (0,1)), mode='same') > 0) |\\\n",
    "        ma_mask | (correlate2d(ma_mask, np.flip(ma_tri_template, (0,1)), mode='same') > 0)\n",
    "    )\n",
    "    points = xyzrgb[ref_mask]\n",
    "\n",
    "    ref_id = np.full(ref_mask.shape, -1, np.int32)\n",
    "    ref_id[ref_mask] = np.arange(ref_mask.sum())\n",
    "    faces_lo_tri = np.stack([\n",
    "        ref_id[lo_mask],\n",
    "        ref_id[shift(lo_mask, [1, 0], cval=False, order=0)],\n",
    "        ref_id[shift(lo_mask, [1, 1], cval=False, order=0)],\n",
    "    ], 1)\n",
    "    faces_up_tri = np.stack([\n",
    "        ref_id[up_mask],\n",
    "        ref_id[shift(up_mask, [1, 1], cval=False, order=0)],\n",
    "        ref_id[shift(up_mask, [0, 1], cval=False, order=0)],\n",
    "    ], 1)\n",
    "    faces_ma_tri = np.stack([\n",
    "        ref_id[ma_mask],\n",
    "        ref_id[shift(ma_mask, [1, 0], cval=False, order=0)],\n",
    "        ref_id[shift(ma_mask, [0, 1], cval=False, order=0)],\n",
    "    ], 1)\n",
    "    faces = np.concatenate([faces_lo_tri, faces_up_tri, faces_ma_tri])\n",
    "\n",
    "    # Visualize result as 3d mesh\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Mesh3d(\n",
    "                x=points[:,0],\n",
    "                y=points[:,1],\n",
    "                z=points[:,2],\n",
    "                i=faces[:,0],\n",
    "                j=faces[:,1],\n",
    "                k=faces[:,2],\n",
    "                facecolor=points[:,3:][faces[:,0]])\n",
    "        ],\n",
    "        layout=dict(\n",
    "            scene=dict(\n",
    "                xaxis=dict(visible=False),\n",
    "                yaxis=dict(visible=False),\n",
    "                zaxis=dict(visible=False)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.write_html(f'./HoHoNet/assets/output/figure/html/{name2}.html')\n",
    "    fig.write_json(f'./HoHoNet/assets/output/figure/json/{name2}.json')\n",
    "\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}